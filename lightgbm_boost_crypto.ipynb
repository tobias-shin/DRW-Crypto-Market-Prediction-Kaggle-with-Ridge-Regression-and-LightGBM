{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1341e02-cbc0-4ec3-8ec4-69ec21824439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aab1116-5375-43ef-9323-d5a2572cb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads cleaned data\n",
    "df = pd.read_parquet(\"/Users/tobiasshin/Downloads/cleaned_data.parquet\")\n",
    "\n",
    "df_test = pd.read_parquet(\"/Users/tobiasshin/Downloads/cleaned_test_data.parquet\")\n",
    "\n",
    "lightgbm_model = joblib.load(\"lightgbm_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cbe1f6-2385-4110-a59d-d007aae0517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     bid_qty  ask_qty  buy_qty  sell_qty   volume        X1  \\\n",
      "2023-03-01 00:00:00   15.283    8.425  176.405    44.984  221.389  0.181844   \n",
      "2023-03-01 00:01:00   38.590    2.336  525.846   321.950  847.796  0.489497   \n",
      "2023-03-01 00:02:00    0.442   60.250  159.227   136.369  295.596  0.260121   \n",
      "2023-03-01 00:03:00    4.865   21.016  335.742   124.963  460.705  0.099976   \n",
      "2023-03-01 00:04:00   27.158    3.451   98.411    44.407  142.818  0.270893   \n",
      "\n",
      "                           X2        X3        X4        X5  ...      X772  \\\n",
      "2023-03-01 00:00:00 -0.637860  0.006652  0.136870  0.116698  ...  0.333753   \n",
      "2023-03-01 00:01:00 -0.075619  0.431594  0.522400  0.475255  ...  0.333657   \n",
      "2023-03-01 00:02:00 -0.444684  0.100695  0.224729  0.203282  ...  0.333667   \n",
      "2023-03-01 00:03:00 -0.666728 -0.123858  0.019197  0.014459  ...  0.333174   \n",
      "2023-03-01 00:04:00 -0.325973  0.116336  0.234311  0.214073  ...  0.333171   \n",
      "\n",
      "                         X773      X774      X775      X776      X777  \\\n",
      "2023-03-01 00:00:00 -0.009992 -0.695595 -0.444077 -0.191238 -0.184251   \n",
      "2023-03-01 00:01:00 -0.010040 -0.696226 -0.452866 -0.200082 -0.188929   \n",
      "2023-03-01 00:02:00 -0.010037 -0.696832 -0.461383 -0.208786 -0.193571   \n",
      "2023-03-01 00:03:00 -0.010279 -0.697391 -0.469628 -0.217350 -0.198175   \n",
      "2023-03-01 00:04:00 -0.010283 -0.697940 -0.477622 -0.225780 -0.202745   \n",
      "\n",
      "                         X778      X779      X780     label  \n",
      "2023-03-01 00:00:00 -0.471897 -0.625428 -0.553991  0.562539  \n",
      "2023-03-01 00:01:00 -0.472842 -0.625832 -0.554426  0.533686  \n",
      "2023-03-01 00:02:00 -0.473785 -0.626236 -0.554860  0.546505  \n",
      "2023-03-01 00:03:00 -0.474726 -0.626639 -0.555294  0.357703  \n",
      "2023-03-01 00:04:00 -0.475666 -0.627043 -0.555728  0.362452  \n",
      "\n",
      "[5 rows x 786 columns]\n",
      "(525886, 786)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run cell 2 and 3 once, just to clean data\n",
    "    From then on, just reload cleaned data from cell 1\n",
    "    Will be commented out after cleaned\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"/Users/tobiasshin/Downloads/drw-crypto-market-prediction/train.parquet\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06261398-8764-4e1c-8f7f-447fba9ff43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# drop all features that are all constant (variance 0)\n",
    "zero_var = df.loc[:, df.nunique() == 1]\n",
    "df = df.drop(columns=zero_var)\n",
    "print(zero_var.columns)\n",
    "\n",
    "# save cleaned data set\n",
    "df.to_parquet(\"/Users/tobiasshin/Downloads/cleaned_data.parquet\") \n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5f39b5-b13f-41c0-bb7f-bf0d3510b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation with the label\n",
    "correlations = df.corr(numeric_only=True)[\"label\"].drop(\"label\")  # drop label itself\n",
    "\n",
    "# Sort by absolute correlation\n",
    "top_corr_features = correlations.abs().sort_values(ascending=False).head(20).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfeeecd-6a2a-4a05-aee4-14a1e041cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_outliers(train_df, test_df, lower=0.01, upper=0.99):\n",
    "    lower_bounds = train_df.quantile(lower)\n",
    "    upper_bounds = train_df.quantile(upper)\n",
    "    return (\n",
    "        train_df.clip(lower=lower_bounds, upper=upper_bounds, axis=1),\n",
    "        test_df.clip(lower=lower_bounds, upper=upper_bounds, axis=1)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3b76d9-3746-4936-bb4e-fc06875ef205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's try gradient boosting on the full data set\n",
    "\n",
    "\n",
    "# 1. Split data chronologically\n",
    "split_index = int(0.8 * len(df))\n",
    "train = df.iloc[:split_index]\n",
    "test = df.iloc[split_index:]\n",
    "\n",
    "# 2. Prepare features and target\n",
    "X_train = train.drop(columns=[\"label\"])\n",
    "y_train = train[\"label\"]\n",
    "X_test = test.drop(columns=[\"label\"])\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "# 3. Clip the training and test data\n",
    "X_train_clipped, X_test_clipped = clip_outliers(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d269ef39-e084-4062-99c3-cd35dbd1012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.204758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 200173\n",
      "[LightGBM] [Info] Number of data points in the train set: 420708, number of used features: 785\n",
      "[LightGBM] [Info] Start training from score 0.025639\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's l2: 1.18424\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's l2: 1.08265\n",
      "MSE: 1.0826\n",
      "R²: -0.0025\n"
     ]
    }
   ],
   "source": [
    "# The above cell takes way too long, we use light GBM instead\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=1000,        # allow early stopping to cut it off early\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,            # randomly sample rows\n",
    "    colsample_bytree=0.8,     # randomly sample features\n",
    "    n_jobs=-1,                # use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with early stopping on test set\n",
    "\n",
    "model.fit(\n",
    "    X_train_clipped, y_train,\n",
    "    eval_set=[(X_test_clipped, y_test)],\n",
    "    eval_metric=\"l2\",\n",
    "    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(50)]\n",
    ")\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test_clipped)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d4841a-bb8c-4e70-9030-434171221c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0799601349846195\n"
     ]
    }
   ],
   "source": [
    "print(y_test.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93e0b87-268c-4631-b66b-24fa49336a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between prediction and label: 0.0430\n"
     ]
    }
   ],
   "source": [
    "correlation = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "print(f\"Correlation between prediction and label: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "825aba4d-7ae5-4305-8f99-78aba0ad4f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538150, 786)\n",
      "    bid_qty  ask_qty  buy_qty  sell_qty   volume        X1        X2  \\\n",
      "ID                                                                     \n",
      "1     0.317    8.102   13.164    10.272   23.436 -0.341229  0.041851   \n",
      "2     2.608    2.111  123.562    40.163  163.725 -1.029564 -1.382505   \n",
      "3     2.768   10.787  126.137   118.266  244.403 -2.594090 -5.486158   \n",
      "4     0.948   12.157   16.069    31.723   47.792  0.240745  0.997585   \n",
      "5     1.084    3.493   32.679    37.327   70.006  0.067189  0.772852   \n",
      "\n",
      "          X3        X4        X5  ...      X772      X773      X774      X775  \\\n",
      "ID                                ...                                           \n",
      "1  -0.020094 -0.206221 -0.297124  ... -0.147911 -0.043417  1.521787  1.548965   \n",
      "2  -1.214935 -1.020241 -0.960397  ... -0.126703 -0.077090 -0.703054 -0.716951   \n",
      "3  -4.744466 -3.930152 -3.275324  ... -0.147750 -0.030627 -0.703514 -0.717525   \n",
      "4   1.028965  1.081052  0.811895  ... -0.136737 -0.033380  1.521167  1.551771   \n",
      "5   0.772152  0.714846  0.514422  ... -0.218991 -0.004915 -0.703161 -0.716900   \n",
      "\n",
      "        X776      X777      X778      X779      X780  label  \n",
      "ID                                                           \n",
      "1   1.495735  1.166730  0.281056 -0.187831 -0.599553      0  \n",
      "2  -0.721292 -0.674619 -0.639318 -0.736268 -0.862220      0  \n",
      "3  -0.731701 -0.750998 -0.789366 -0.850941 -1.033131      0  \n",
      "4   1.582833  1.625830  1.762155  1.911924  1.962445      0  \n",
      "5  -0.714699 -0.652209 -0.623165 -0.699887 -0.640094      0  \n",
      "\n",
      "[5 rows x 786 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let's apply above model to the test data\n",
    "\n",
    "df_test = pd.read_parquet(\"/Users/tobiasshin/Downloads/drw-crypto-market-prediction/test.parquet\")\n",
    "print(df_test.shape)\n",
    "print(df_test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66ae6a4-6f1a-419a-88eb-15406c9cb80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# drop all features that are all constant (variance 0)\n",
    "zero_var = df_test.loc[:, df_test.nunique() == 1]\n",
    "df = df_test.drop(columns=zero_var)\n",
    "print(zero_var.columns)\n",
    "\n",
    "# save cleaned data set\n",
    "df_test.to_parquet(\"/Users/tobiasshin/Downloads/cleaned_test_data.parquet\") \n",
    "df_test.to_csv(\"cleaned_test_data.csv\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd2e4d8-1ce0-43fb-8704-98aa192065e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=[\"label\"])\n",
    "y_test = df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ae75ef-7bd0-4fb8-b165-83100803ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"label\"])\n",
    "y_train = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8e4b08-f027-47d6-b155-cdc6b746500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clipped, X_test_clipped = clip_outliers(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577fc83c-ffbe-4ce6-8d1a-83e105279d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = X_train_clipped.columns.tolist()\n",
    "X_test = X_test[feature_columns]\n",
    "\n",
    "X_train_clipped, X_test_clipped = clip_outliers(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6650059f-4c9d-45d5-8c1b-d474d71c4e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 200173\n",
      "[LightGBM] [Info] Number of data points in the train set: 420708, number of used features: 785\n",
      "[LightGBM] [Info] Start training from score 0.025639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lightgbm_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrain model on all training data WITHOUT validation set\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=1000,  # if early stopping told you 180 rounds, set n_estimators=180\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_clipped, y_train)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, \"lightgbm_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf200cb7-4f3e-4569-9fdc-4bcfdd1d6584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420708, 785)\n",
      "(538150, 785)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_clipped.shape)\n",
    "print(X_test_clipped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b778fdd-11bb-47aa-a640-32233737f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_clipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2659612b-0469-4db2-acdf-d529a84a28a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538150,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529a1870-8c17-40a3-b715-69fd64e68240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538150\n"
     ]
    }
   ],
   "source": [
    "print(X_test_clipped.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "095e474b-3ee0-4947-9bd8-8d91d6dc1c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred std dev: 0.7919130449233909\n",
      "y_pred unique values: [-5.10374362 -4.75894121 -4.66580793 ...  6.45280346  6.50889712\n",
      "  6.55739305]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred std dev:\", np.std(y_pred))\n",
    "print(\"y_pred unique values:\", np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ec42c59-be64-47e7-bba7-47ffca43f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume', 'X1', 'X2', 'X3',\n",
      "       'X4', 'X5',\n",
      "       ...\n",
      "       'X772', 'X773', 'X774', 'X775', 'X776', 'X777', 'X778', 'X779', 'X780',\n",
      "       'label'],\n",
      "      dtype='object', length=786)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67b06675-4e0a-4319-828a-3edbc2a61fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'prediction'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('/Users/tobiasshin/Downloads/sample_submission.csv')\n",
    "print(sample_sub.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aba4c72-974a-4887-acef-e60dc713c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission dataframe, for example if there's an ID column 'id'\n",
    "submission = pd.DataFrame({\n",
    "    'ID': sample_sub['ID'],  # or the correct ID column\n",
    "    'prediction': y_pred     # or whatever the competition target is called\n",
    "})\n",
    "\n",
    "# Save to CSV for submission\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe6dc2-5f21-41a4-9f5c-fb0261944787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK so they changed the training set so now we have to re-clean and re-explore and then re-train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
